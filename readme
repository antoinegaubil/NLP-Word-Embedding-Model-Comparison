This project explores the performance of different word embedding models, such as Word2Vec and GloVe, through synonym tests. The evaluation includes model comparison based on corpus sizes and custom models trained on book data, providing insights into the strengths and weaknesses of each approach. The accompanying analysis.csv file presents detailed results, and visualizations offer a comprehensive overview of the models' accuracy across different parameters.
